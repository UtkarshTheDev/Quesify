---
phase: 01-embedding-migration
plan: 03
type: execute
wave: 2
depends_on: [01, 02]
files_modified: [
  src/scripts/backfill-embeddings.ts,
  src/scripts/backfill-embeddings-batch.ts
]
autonomous: true
user_setup:
  - service: supabase
    why: "Need to run backfill script against production database"
    env_vars:
      - name: SUPABASE_SERVICE_ROLE_KEY
        source: "Supabase Dashboard -> Project Settings -> API"
  - service: google-ai
    why: "Need Gemini API key for embedding generation"
    env_vars:
      - name: GEMINI_API_KEY
        source: "Google AI Studio -> API Keys"
must_haves:
  truths:
    - All existing questions have 768-dimension embeddings
    - Backfill uses task_type='retrieval_document' for consistency
    - Progress tracking and resumability implemented
    - Failed batches logged for retry
  artifacts:
    - path: src/scripts/backfill-embeddings.ts
      provides: Full backfill script
      contains: "taskType: 'retrieval_document'"
    - path: src/scripts/backfill-embeddings-batch.ts
      provides: Batch processing helper
      exports: ["processBatch", "getQuestionsWithoutEmbeddings"]
  key_links:
    - from: backfill script
      to: questions.embedding column
      via: Supabase client
---

<objective>
Generate 768-dimension embeddings for all existing questions using gemini-embedding-001 model.

Purpose: Migrate existing question embeddings from text-embedding-004 to gemini-embedding-001.
Output: All questions in database have valid 768-dimension embeddings for semantic search.

Why 768 dimensions?
- 2x improvement over old 768-dimension text-embedding-004
- Optimal for short educational content (MCQs, questions)
- 50% less storage than 3072 (scalable to 100K+ questions)
- Faster similarity search queries
</objective>

<execution_context>
@/home/utkarsh/.config/opencode/get-shit-done/workflows/execute-plan.md
</execution_context>

<context>
@/home/utkarsh/development/quesify/src/lib/ai/client.ts
@/home/utkarsh/development/quesify/src/lib/supabase/client.ts

Current state after Plans 01 and 02:
- Database schema updated to VECTOR(768) (optimal for educational content)
- All existing embeddings are NULL (from ALTER COLUMN)
- AI client ready with gemini-embedding-001 at 768 dimensions
- Need to regenerate embeddings for all questions

Batch processing considerations:
- Rate limits: Gemini API has quotas
- Time: Thousands of questions could take hours
- Resumability: Script must handle interruptions
- Progress tracking: Need visibility into completion
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Batch Backfill Script</name>
  <files>src/scripts/backfill-embeddings.ts</files>
  <action>
    Create a comprehensive backfill script that regenerates embeddings for all questions.
    
    Requirements:
    1. Fetch questions in batches (e.g., 50-100 at a time)
    2. Generate embeddings using gemini-embedding-001 with task_type='retrieval_document'
    3. Update database with new embeddings
    4. Track progress and handle failures gracefully
    5. Support resumability (can restart from where it left off)
    6. Respect API rate limits (add delays between batches)
    
    Script structure:
    ```typescript
    import { createClient } from '@supabase/supabase-js'
    import { getAIClient } from '../lib/ai/client'
    import { Question } from '../lib/types/database'

    const BATCH_SIZE = 50
    const RATE_LIMIT_DELAY_MS = 100 // Adjust based on API limits

    async function backfillEmbeddings() {
      const supabase = createClient(
        process.env.NEXT_PUBLIC_SUPABASE_URL!,
        process.env.SUPABASE_SERVICE_ROLE_KEY! // Needs service role for bulk update
      )
      const ai = getAIClient()

      console.log('Starting embedding backfill...')
      
      let processed = 0
      let failed = 0
      let hasMore = true
      let lastId: string | null = null

      while (hasMore) {
        // Fetch batch of questions without embeddings
        const query = supabase
          .from('questions')
          .select('id, question_text')
          .is('embedding', null)
          .order('id')
          .limit(BATCH_SIZE)
        
        if (lastId) {
          query.gt('id', lastId)
        }

        const { data: questions, error } = await query

        if (error) {
          console.error('Database error:', error)
          break
        }

        if (!questions || questions.length === 0) {
          hasMore = false
          break
        }

        console.log(`Processing batch of ${questions.length} questions...`)

        // Process each question in batch
        for (const question of questions) {
          try {
            // Generate embedding with task_type for document indexing
            const embedding = await ai.generateEmbedding(
              question.question_text,
              'retrieval_document'
            )

            // Update database
            const { error: updateError } = await supabase
              .from('questions')
              .update({ embedding })
              .eq('id', question.id)

            if (updateError) {
              console.error(`Failed to update ${question.id}:`, updateError)
              failed++
            } else {
              processed++
            }

            // Rate limiting
            await new Promise(resolve => setTimeout(resolve, RATE_LIMIT_DELAY_MS))
          } catch (err) {
            console.error(`Failed to process ${question.id}:`, err)
            failed++
          }
        }

        lastId = questions[questions.length - 1].id
        console.log(`Progress: ${processed} processed, ${failed} failed`)
      }

      console.log('Backfill complete!')
      console.log(`Total processed: ${processed}`)
      console.log(`Total failed: ${failed}`)
    }

    // Run if executed directly
    if (require.main === module) {
      backfillEmbeddings().catch(console.error)
    }

    export { backfillEmbeddings }
    ```
  </action>
  <verify>Script created with batch processing, error handling, and progress tracking</verify>
  <done>Backfill script implemented with resumability</done>
</task>

<task type="auto">
  <name>Task 2: Create Batch Helper Functions</name>
  <files>src/scripts/backfill-embeddings-batch.ts</files>
  <action>
    Create reusable batch processing utilities for the backfill.
    
    Functions needed:
    1. `getQuestionsWithoutEmbeddings(batchSize, lastId)` - Fetch next batch
    2. `updateQuestionEmbedding(questionId, embedding)` - Update single question
    3. `processBatch(questions, ai, supabase)` - Process batch with retries
    4. `logProgress(processed, failed, total)` - Progress tracking
    
    Also add:
    - Retry logic with exponential backoff
    - Failed question logging (to file for later retry)
    - Checkpoint saving (resume file)
    
    ```typescript
    export async function processBatch(
      questions: Question[],
      ai: AIClient,
      supabase: SupabaseClient,
      options: { retries?: number; delayMs?: number } = {}
    ): Promise<{ processed: number; failed: string[] }> {
      const { retries = 3, delayMs = 100 } = options
      const failed: string[] = []
      let processed = 0

      for (const question of questions) {
        let attempt = 0
        let success = false

        while (attempt < retries && !success) {
          try {
            const embedding = await ai.generateEmbedding(
              question.question_text,
              'retrieval_document'
            )

            const { error } = await supabase
              .from('questions')
              .update({ embedding })
              .eq('id', question.id)

            if (error) throw error
            
            success = true
            processed++
          } catch (err) {
            attempt++
            if (attempt >= retries) {
              failed.push(question.id)
              console.error(`Failed after ${retries} attempts: ${question.id}`, err)
            } else {
              await new Promise(r => setTimeout(r, delayMs * attempt))
            }
          }
        }

        await new Promise(r => setTimeout(r, delayMs))
      }

      return { processed, failed }
    }
    ```
  </action>
  <verify>Batch helper functions created with retry logic</verify>
  <done>Reusable batch utilities implemented</done>
</task>

<task type="auto">
  <name>Task 3: Create Progress and Resume Utilities</name>
  <files>src/scripts/backfill-progress.ts</files>
  <action>
    Create utilities for tracking progress and resuming interrupted backfills.
    
    Features:
    1. Save checkpoint (last processed ID, counts)
    2. Load checkpoint (resume from saved state)
    3. Progress statistics (total questions, completed, remaining, ETA)
    4. Failed items log (for retry later)
    
    ```typescript
    import { writeFile, readFile } from 'fs/promises'
    import { createClient } from '@supabase/supabase-js'

    interface Checkpoint {
      lastId: string | null
      processed: number
      failed: number
      timestamp: string
    }

    const CHECKPOINT_FILE = '.backfill-checkpoint.json'
    const FAILED_LOG_FILE = '.backfill-failed.json'

    export async function saveCheckpoint(checkpoint: Checkpoint): Promise<void> {
      await writeFile(CHECKPOINT_FILE, JSON.stringify(checkpoint, null, 2))
    }

    export async function loadCheckpoint(): Promise<Checkpoint | null> {
      try {
        const data = await readFile(CHECKPOINT_FILE, 'utf-8')
        return JSON.parse(data)
      } catch {
        return null
      }
    }

    export async function logFailed(failedIds: string[]): Promise<void> {
      const existing = await readFile(FAILED_LOG_FILE, 'utf-8').catch(() => '[]')
      const all = [...JSON.parse(existing), ...failedIds]
      await writeFile(FAILED_LOG_FILE, JSON.stringify(all, null, 2))
    }

    export async function getProgress(supabase: SupabaseClient): Promise<{
      total: number
      withEmbedding: number
      withoutEmbedding: number
      percentComplete: number
    }> {
      const { count: total } = await supabase
        .from('questions')
        .select('*', { count: 'exact', head: true })

      const { count: withEmbedding } = await supabase
        .from('questions')
        .select('*', { count: 'exact', head: true })
        .not('embedding', 'is', null)

      return {
        total: total || 0,
        withEmbedding: withEmbedding || 0,
        withoutEmbedding: (total || 0) - (withEmbedding || 0),
        percentComplete: total ? ((withEmbedding || 0) / total) * 100 : 0
      }
    }
    ```
  </action>
  <verify>Progress tracking utilities created</verify>
  <done>Checkpoint and progress utilities implemented</done>
</task>

<task type="auto">
  <name>Task 4: Create Retry Script for Failed Items</name>
  <files>src/scripts/backfill-retry.ts</files>
  <action>
    Create a script to retry failed embeddings from the failed log.
    
    ```typescript
    import { createClient } from '@supabase/supabase-js'
    import { readFile } from 'fs/promises'
    import { getAIClient } from '../lib/ai/client'

    const FAILED_LOG_FILE = '.backfill-failed.json'

    async function retryFailed() {
      const failedIds: string[] = JSON.parse(
        await readFile(FAILED_LOG_FILE, 'utf-8').catch(() => '[]')
      )

      if (failedIds.length === 0) {
        console.log('No failed items to retry')
        return
      }

      console.log(`Retrying ${failedIds.length} failed items...`)

      const supabase = createClient(
        process.env.NEXT_PUBLIC_SUPABASE_URL!,
        process.env.SUPABASE_SERVICE_ROLE_KEY!
      )
      const ai = getAIClient()

      let success = 0
      const stillFailed: string[] = []

      for (const id of failedIds) {
        try {
          const { data: question } = await supabase
            .from('questions')
            .select('question_text')
            .eq('id', id)
            .single()

          if (!question) {
            console.log(`Question ${id} not found, skipping`)
            continue
          }

          const embedding = await ai.generateEmbedding(
            question.question_text,
            'retrieval_document'
          )

          const { error } = await supabase
            .from('questions')
            .update({ embedding })
            .eq('id', id)

          if (error) throw error
          success++
        } catch (err) {
          console.error(`Retry failed for ${id}:`, err)
          stillFailed.push(id)
        }

        await new Promise(r => setTimeout(r, 200))
      }

      console.log(`Retry complete: ${success} succeeded, ${stillFailed.length} still failed`)
      
      // Update failed log
      await writeFile(FAILED_LOG_FILE, JSON.stringify(stillFailed, null, 2))
    }

    retryFailed().catch(console.error)
    ```
  </action>
  <verify>Retry script created for failed items</verify>
  <done>Retry mechanism implemented</done>
</task>

<task type="auto">
  <name>Task 5: Create Execution Guide</name>
  <files>scripts/BACKFILL_GUIDE.md</files>
  <action>
    Create documentation for running the backfill in production.
    
    Include:
    1. Prerequisites (env vars, API keys)
    2. Pre-flight checks (estimate time, verify schema)
    3. Running the backfill (commands, monitoring)
    4. Handling interruptions (resume process)
    5. Retry failed items
    6. Verification steps
    7. Rollback plan if needed
    
    Example structure:
    ```markdown
    # Embedding Backfill Guide

    ## Prerequisites
    - Ensure Plans 01 and 02 are complete
    - Verify database schema is VECTOR(3072)
    - Confirm GEMINI_API_KEY has sufficient quota

    ## Pre-flight
    ```bash
    # Check how many questions need embeddings
    npx tsx src/scripts/backfill-progress.ts
    ```

    ## Run Backfill
    ```bash
    # Start backfill (resumable)
    npx tsx src/scripts/backfill-embeddings.ts
    ```

    ## Monitor Progress
    In another terminal:
    ```bash
    npx tsx src/scripts/backfill-progress.ts
    ```

    ## Retry Failed
    ```bash
    npx tsx src/scripts/backfill-retry.ts
    ```
    ```
  </action>
  <verify>Backfill guide created with clear instructions</verify>
  <done>Execution documentation complete</done>
</task>

</tasks>

<verification>
- [ ] Backfill script created with batch processing
- [ ] Batch helper functions with retry logic
- [ ] Progress tracking and checkpoint utilities
- [ ] Retry script for failed items
- [ ] Execution guide created
- [ ] All scripts compile without TypeScript errors
</verification>

<success_criteria>
Ready to run full embedding backfill with progress tracking, resumability, and failure recovery.
</success_criteria>

<output>
After completion, create `.planning/phases/01-embedding-migration/01-03-SUMMARY.md`
</output>
