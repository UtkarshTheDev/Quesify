---
phase: 01-embedding-migration
plan: 02
type: execute
wave: 1
depends_on: []
files_modified: [
  src/lib/ai/config.ts,
  src/lib/ai/client.ts,
  .env.example,
  .env.local
]
autonomous: true
must_haves:
  truths:
    - AI_CONFIG uses gemini-embedding-001 model
    - generateEmbedding uses task_type parameter
    - Embedding dimension set to 768 (matching database schema)
    - Environment variables documented
  artifacts:
    - path: src/lib/ai/config.ts
      provides: Updated embedding model configuration
      contains: "gemini-embedding-001"
    - path: src/lib/ai/client.ts
      provides: Enhanced embedding generation with task_type
      contains: "taskType: 'retrieval_document'"
  key_links:
    - from: src/lib/ai/config.ts embedding config
      to: src/lib/ai/client.ts generateEmbedding
      via: AI_CONFIG.models.embedding
---

<objective>
Update AI client code to use gemini-embedding-001 with 768 dimensions (matching existing database schema).

Purpose: Upgrade to gemini-embedding-001 while keeping database compatibility - NO schema changes needed!
Output: Updated AI client with new model, task types, and 768-dimension configuration.

Why 768 dimensions?
- Database already has VECTOR(768) - no schema migration needed
- HNSW index already works with 768
- Function already uses VECTOR(768)
- Much simpler migration - just regenerate embeddings
- Still gets gemini-embedding-001 quality improvements
</objective>

<execution_context>
@/home/utkarsh/.config/opencode/get-shit-done/workflows/execute-plan.md
</execution_context>

<context>
@/home/utkarsh/development/quesify/src/lib/ai/config.ts
@/home/utkarsh/development/quesify/src/lib/ai/client.ts

Current implementation:
- Model: "text-embedding-004" (deprecated Feb 2026)
- Dimension: 768 (hardcoded outputDimensionality: 768)
- No task_type parameter
- Basic embedContent call

New gemini-embedding-001 features:
- 3072 dimensions default, configurable to 768/1536
- task_type: retrieval_document (for indexing) / retrieval_query (for search)
- Better semantic understanding for educational content
- February 14, 2026 deadline for migration
- KEEPING 768: Database already VECTOR(768), no schema changes needed!
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update AI_CONFIG embedding model</name>
  <files>src/lib/ai/config.ts</files>
  <action>
    Update the embedding configuration in AI_CONFIG to use gemini-embedding-001.
    
    Changes needed:
    1. Update model name from "text-embedding-004" to "gemini-embedding-001"
    2. Keep dimension at 768 (matching database schema)
    3. Add outputDimensionality: 768 to API calls
    4. Add task_type options documentation
    
    Update this section:
    ```typescript
    // Embedding model (Gemini embedding for semantic search)
    // Keeping 768 dimensions to match existing database schema
    // - No schema migration needed
    // - No index recreation needed
    // - No function updates needed
    // Still gets gemini-embedding-001 quality improvements
    embedding: {
        provider: "gemini",
        model: process.env.AI_MODEL_EMBEDDING || "gemini-embedding-001",
        dimension: 768, // Keep existing - no schema changes needed
        outputDimensionality: 768, // Explicit for API call
        taskTypes: {
            document: "retrieval_document", // For indexing questions
            query: "retrieval_query"        // For searching/duplicate detection
        }
    } as ModelConfig & { dimension: number; outputDimensionality: number; taskTypes: Record<string, string> },
    ```
    
    Also update the type definition to include the new fields:
    ```typescript
    export interface ModelConfig {
        provider: AIProvider;
        model: string;
        dimension?: number;        // For embedding models
        taskTypes?: Record<string, string>; // For embedding task types
    }
    ```
  </action>
  <verify>config.ts updated with gemini-embedding-001 and dimension/taskTypes</verify>
  <done>AI_CONFIG.embedding uses new model with proper metadata</done>
</task>

<task type="auto">
  <name>Task 2: Enhance generateEmbedding with task_type</name>
  <files>src/lib/ai/client.ts</files>
  <action>
    Update the generateEmbedding method to support task_type parameter and use 768 dimensions (matching database).
    
    Changes:
    1. Keep outputDimensionality: 768 (matching database schema)
    2. Add taskType parameter
    3. Update to use gemini-embedding-001 model
    
    Update to:
    ```typescript
    /**
     * Generate text embedding for semantic search
     * Uses gemini-embedding-001 with 768 dimensions (matching database schema)
     * 
     * @param text - Text to embed
     * @param taskType - Task type for optimization:
     *   - 'retrieval_document': Use when indexing/storing questions (upload flow)
     *   - 'retrieval_query': Use when searching for duplicates (query flow)
     * @returns 768-dimension embedding vector
     */
    async generateEmbedding(
      text: string, 
      taskType: 'retrieval_document' | 'retrieval_query' = 'retrieval_document'
    ): Promise<number[]> {
      const config = AI_CONFIG.models.embedding
      const start = performance.now()
      
      if (config.provider !== 'gemini') {
        throw new Error('Only Gemini provider is supported for embeddings currently')
      }

      const model = this.getGeminiModel(config.model)
      
      const request: EmbedContentRequest = {
        content: { role: 'user', parts: [{ text }] },
        taskType: taskType,
        outputDimensionality: 768, // Keep 768 to match database schema
      }
      
      const result = await model.embedContent(request)

      const duration = performance.now() - start
      if (AI_CONFIG.debug) {
        console.log(`[AI/Embedding] task=${taskType} dim=768 took ${duration.toFixed(2)}ms`)
      }
      
      return result.embedding.values
    }
    ```
    
    Also update the import to use proper EmbedContentRequest type.
  </action>
  <verify>client.ts updated with taskType parameter and proper EmbedContentRequest</verify>
  <done>generateEmbedding supports task types and produces 3072-dimension vectors</done>
</task>

<task type="auto">
  <name>Task 3: Update environment variable documentation</name>
  <files>.env.example</files>
  <action>
    Update .env.example to document the new embedding model environment variable.
    
    Add or update:
    ```env
    # AI Model Configuration
    # Embedding model (default: gemini-embedding-001)
    # Model: gemini-embedding-001 (state-of-the-art, replaces deprecated text-embedding-004)
    # Dimension: 768 (matching existing database schema - NO MIGRATION NEEDED)
    # 
    # Why 768?
    # - Database already has VECTOR(768)
    # - No schema changes needed
    # - No index recreation needed
    # - Simpler migration process
    # - Still gets gemini-embedding-001 quality improvements
    AI_MODEL_EMBEDDING=gemini-embedding-001
    
    # Embedding Configuration:
    # - outputDimensionality: 768 (matching database)
    # - taskType: retrieval_document (indexing) / retrieval_query (search)
    ```
    
    Also check if there's a README section about environment variables and update it with the new info.
  </action>
  <verify>.env.example updated with gemini-embedding-001 documentation</verify>
  <done>Environment variables documented for new model</done>
</task>

<task type="auto">
  <name>Task 4: Update all embedding generation call sites</name>
  <files>src/app/api/upload/finalize/route.ts, src/app/api/questions/route.ts</files>
  <action>
    Find and update all places that call generateEmbedding to use the new signature.
    
    Check these files:
    1. src/app/api/upload/finalize/route.ts
       - Should use 'retrieval_document' task type (indexing new question)
    2. src/app/api/questions/route.ts
       - Should use 'retrieval_query' task type (searching for duplicates)
    
    Update calls:
    ```typescript
    // Old
    const embedding = await ai.generateEmbedding(question_text)
    
    // New
    const embedding = await ai.generateEmbedding(question_text, 'retrieval_document')
    ```
    
    For search/duplicate detection:
    ```typescript
    // Old
    const embedding = await ai.generateEmbedding(searchText)
    
    // New
    const embedding = await ai.generateEmbedding(searchText, 'retrieval_query')
    ```
    
    Use grep to find all occurrences and update them.
  </action>
  <verify>All generateEmbedding calls updated with appropriate taskType</verify>
  <done>All call sites use task types correctly</done>
</task>

</tasks>

<verification>
- [ ] src/lib/ai/config.ts updated with gemini-embedding-001
- [ ] src/lib/ai/client.ts updated with task_type support
- [ ] .env.example updated with new model documentation
- [ ] All generateEmbedding call sites updated
- [ ] No TypeScript errors
</verification>

<success_criteria>
AI client ready to generate 768-dimension embeddings with gemini-embedding-001 (matching database schema - no migration needed).
</success_criteria>

<output>
After completion, create `.planning/phases/01-embedding-migration/01-02-SUMMARY.md`
</output>
