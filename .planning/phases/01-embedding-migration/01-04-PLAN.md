---
phase: 01-embedding-migration
plan: 04
type: execute
wave: 2
depends_on: [03]
files_modified: [
  src/scripts/verify-embeddings.ts,
  src/scripts/test-similarity-search.ts,
  src/scripts/benchmark-embeddings.ts
]
autonomous: false
user_setup:
  - service: supabase
    why: "Need to verify embeddings in production database"
  - service: gemini
    why: "Need to test embedding quality"
must_haves:
  truths:
    - All questions have valid 768-dimension embeddings
    - Similarity search returns accurate results
    - Performance metrics within acceptable range
    - No null embeddings remaining
  artifacts:
    - path: src/scripts/verify-embeddings.ts
      provides: Verification script
      contains: "dimension === 3072"
    - path: src/scripts/test-similarity-search.ts
      provides: Search quality testing
      exports: ["testSimilaritySearch"]
  key_links:
    - from: verification script
      to: questions.embedding column
      via: Supabase query
---

<objective>
Validate the embedding migration by verifying all questions have valid embeddings and similarity search works correctly.

Purpose: Ensure the migration is complete and the new gemini-embedding-001 model provides high-quality search results.
Output: Verification report showing 100% coverage and search quality metrics.
</objective>

<execution_context>
@/home/utkarsh/.config/opencode/get-shit-done/workflows/execute-plan.md
</execution_context>

<context>
After Plans 01, 02, and 03:
- Database schema: VECTOR(768) ‚úì
- AI client: gemini-embedding-001 with task_type at 768 dims ‚úì
- Embeddings: All regenerated with new model ‚úì

Now need to verify:
1. 100% of questions have embeddings
2. All embeddings are 768 dimensions (optimal for educational content)
3. Similarity search returns meaningful results
4. Performance is acceptable (<500ms for search)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Embedding Verification Script</name>
  <files>src/scripts/verify-embeddings.ts</files>
  <action>
    Create a comprehensive verification script that checks:
    1. All questions have non-null embeddings
    2. All embeddings have exactly 3072 dimensions
    3. No duplicate or invalid embeddings
    4. Sample verification (spot check 10 random embeddings)
    
    ```typescript
    import { createClient } from '@supabase/supabase-js'

    interface VerificationResult {
      totalQuestions: number
      withEmbedding: number
      withoutEmbedding: number
      coverage: number
      dimensionChecks: {
        passed: number
        failed: number
        details: Array<{ id: string; dimensions: number }>
      }
      nullChecks: {
        passed: boolean
        nullCount: number
      }
    }

    async function verifyEmbeddings(): Promise<VerificationResult> {
      const supabase = createClient(
        process.env.NEXT_PUBLIC_SUPABASE_URL!,
        process.env.SUPABASE_SERVICE_ROLE_KEY!
      )

      console.log('üîç Verifying embeddings...\n')

      // Get counts
      const { count: total } = await supabase
        .from('questions')
        .select('*', { count: 'exact', head: true })
        .is('deleted_at', null)

      const { count: withEmbedding } = await supabase
        .from('questions')
        .select('*', { count: 'exact', head: true })
        .is('deleted_at', null)
        .not('embedding', 'is', null)

      const withoutEmbedding = (total || 0) - (withEmbedding || 0)
      const coverage = total ? ((withEmbedding || 0) / total) * 100 : 0

      console.log(`üìä Coverage: ${withEmbedding}/${total} (${coverage.toFixed(2)}%)`)

      if (withoutEmbedding > 0) {
        console.log(`‚ö†Ô∏è  ${withoutEmbedding} questions without embeddings`)
        
        // Get sample IDs for manual inspection
        const { data: missing } = await supabase
          .from('questions')
          .select('id, question_text')
          .is('deleted_at', null)
          .is('embedding', null)
          .limit(10)
        
        console.log('\n‚ùå Missing embeddings:')
        missing?.forEach(q => console.log(`  - ${q.id}: ${q.question_text.substring(0, 50)}...`))
      }

      // Dimension check on sample
      console.log('\nüìè Checking dimensions...')
      const { data: sample } = await supabase
        .from('questions')
        .select('id, embedding')
        .not('embedding', 'is', null)
        .limit(100)

      const dimensionChecks = {
        passed: 0,
        failed: 0,
        details: [] as Array<{ id: string; dimensions: number }>
      }

      for (const q of sample || []) {
        const dims = q.embedding?.length || 0
        if (dims === 3072) {
          dimensionChecks.passed++
        } else {
          dimensionChecks.failed++
          dimensionChecks.details.push({ id: q.id, dimensions: dims })
        }
      }

      console.log(`  ‚úì Correct (3072): ${dimensionChecks.passed}`)
      console.log(`  ‚úó Incorrect: ${dimensionChecks.failed}`)

      if (dimensionChecks.failed > 0) {
        console.log('\n‚ùå Dimension failures:')
        dimensionChecks.details.forEach(d => 
          console.log(`  - ${d.id}: ${d.dimensions} dimensions`)
        )
      }

      const result: VerificationResult = {
        totalQuestions: total || 0,
        withEmbedding: withEmbedding || 0,
        withoutEmbedding,
        coverage,
        dimensionChecks,
        nullChecks: {
          passed: withoutEmbedding === 0,
          nullCount: withoutEmbedding
        }
      }

      // Summary
      console.log('\n' + '='.repeat(50))
      console.log('üìã VERIFICATION SUMMARY')
      console.log('='.repeat(50))
      console.log(`Coverage: ${coverage.toFixed(2)}%`)
      console.log(`Dimensions: ${dimensionChecks.passed}/${sample?.length || 0} correct`)
      console.log(`Status: ${result.nullChecks.passed && dimensionChecks.failed === 0 ? '‚úÖ PASSED' : '‚ùå FAILED'}`)

      return result
    }

    verifyEmbeddings().catch(console.error)
    ```
  </action>
  <verify>Verification script checks coverage, dimensions, and reports issues</verify>
  <done>Comprehensive verification script created</done>
</task>

<task type="auto">
  <name>Task 2: Create Similarity Search Test</name>
  <files>src/scripts/test-similarity-search.ts</files>
  <action>
    Create a test script that validates the similarity search quality.
    
    Test scenarios:
    1. Find similar questions for a given query
    2. Verify results are semantically relevant
    3. Check similarity scores are in expected range
    4. Test edge cases (very short/long queries)
    
    ```typescript
    import { createClient } from '@supabase/supabase-js'
    import { getAIClient } from '../lib/ai/client'

    const TEST_QUERIES = [
      {
        query: "What is the derivative of x squared?",
        expectedSubjects: ["Mathematics", "Calculus"],
        description: "Basic calculus question"
      },
      {
        query: "Newton's laws of motion",
        expectedSubjects: ["Physics"],
        description: "Physics concept"
      },
      {
        query: "Chemical bonding types",
        expectedSubjects: ["Chemistry"],
        description: "Chemistry topic"
      }
    ]

    async function testSimilaritySearch() {
      const supabase = createClient(
        process.env.NEXT_PUBLIC_SUPABASE_URL!,
        process.env.SUPABASE_ANON_KEY!
      )
      const ai = getAIClient()

      console.log('üîç Testing similarity search...\n')

      for (const test of TEST_QUERIES) {
        console.log(`\nTest: ${test.description}`)
        console.log(`Query: "${test.query}"`)

        try {
          // Generate query embedding
          const embedding = await ai.generateEmbedding(test.query, 'retrieval_query')

          // Search for matches
          const { data: matches, error } = await supabase.rpc(
            'match_questions_with_solutions',
            {
              query_embedding: embedding,
              match_threshold: 0.5,
              match_count: 5
            }
          )

          if (error) {
            console.error('  ‚ùå Search error:', error.message)
            continue
          }

          if (!matches || matches.length === 0) {
            console.log('  ‚ö†Ô∏è  No matches found')
            continue
          }

          console.log(`  ‚úì Found ${matches.length} matches`)
          console.log('  Top results:')
          
          matches.slice(0, 3).forEach((match, i) => {
            const similarity = (match.similarity * 100).toFixed(1)
            const text = match.question_text?.substring(0, 60) || 'N/A'
            console.log(`    ${i + 1}. [${similarity}%] ${text}...`)
          })

          // Check similarity scores
          const avgSimilarity = matches.reduce((sum, m) => sum + m.similarity, 0) / matches.length
          console.log(`  Average similarity: ${(avgSimilarity * 100).toFixed(1)}%`)

        } catch (err) {
          console.error('  ‚ùå Test failed:', err)
        }
      }
    }

    testSimilaritySearch().catch(console.error)
    ```
  </action>
  <verify>Similarity search test validates quality and relevance</verify>
  <done>Search quality test script created</done>
</task>

<task type="auto">
  <name>Task 3: Create Performance Benchmark</name>
  <files>src/scripts/benchmark-embeddings.ts</files>
  <action>
    Create a benchmark to measure embedding generation and search performance.
    
    Metrics to track:
    1. Embedding generation latency (p50, p95, p99)
    2. Similarity search latency
    3. Throughput (embeddings/second)
    
    ```typescript
    import { createClient } from '@supabase/supabase-js'
    import { getAIClient } from '../lib/ai/client'

    async function benchmarkEmbeddings() {
      const supabase = createClient(
        process.env.NEXT_PUBLIC_SUPABASE_URL!,
        process.env.SUPABASE_SERVICE_ROLE_KEY!
      )
      const ai = getAIClient()

      console.log('‚ö° Benchmarking embedding performance...\n')

      // Sample texts of varying lengths
      const testTexts = [
        "What is 2+2?", // Short
        "Explain the process of photosynthesis in plants and how it converts light energy into chemical energy.", // Medium
        "A detailed calculus problem involving integration by parts with multiple steps and substitutions..." // Long
      ]

      const latencies: number[] = []

      console.log('Testing embedding generation:')
      for (const text of testTexts) {
        const times: number[] = []
        
        for (let i = 0; i < 5; i++) {
          const start = performance.now()
          await ai.generateEmbedding(text, 'retrieval_document')
          times.push(performance.now() - start)
        }

        const avg = times.reduce((a, b) => a + b) / times.length
        latencies.push(...times)
        
        console.log(`  "${text.substring(0, 40)}..." - Avg: ${avg.toFixed(2)}ms`)
      }

      // Calculate percentiles
      const sorted = latencies.sort((a, b) => a - b)
      const p50 = sorted[Math.floor(sorted.length * 0.5)]
      const p95 = sorted[Math.floor(sorted.length * 0.95)]
      const p99 = sorted[Math.floor(sorted.length * 0.99)]

      console.log('\nüìä Latency Percentiles:')
      console.log(`  p50: ${p50.toFixed(2)}ms`)
      console.log(`  p95: ${p95.toFixed(2)}ms`)
      console.log(`  p99: ${p99.toFixed(2)}ms`)

      // Test search performance
      console.log('\nTesting similarity search:')
      const sampleEmbedding = await ai.generateEmbedding("test query", 'retrieval_query')
      
      const searchTimes: number[] = []
      for (let i = 0; i < 10; i++) {
        const start = performance.now()
        await supabase.rpc('match_questions_with_solutions', {
          query_embedding: sampleEmbedding,
          match_threshold: 0.5,
          match_count: 10
        })
        searchTimes.push(performance.now() - start)
      }

      const avgSearch = searchTimes.reduce((a, b) => a + b) / searchTimes.length
      console.log(`  Avg search time: ${avgSearch.toFixed(2)}ms`)

      console.log('\n‚úÖ Benchmark complete')
    }

    benchmarkEmbeddings().catch(console.error)
    ```
  </action>
  <verify>Benchmark script measures generation and search performance</verify>
  <done>Performance benchmark created</done>
</task>

</tasks>

<verification>
- [ ] Verification script checks 100% coverage
- [ ] Similarity search test validates quality
- [ ] Performance benchmark created
- [ ] All scripts compile without errors
</verification>

<success_criteria>
Verification ready to confirm migration success with coverage, quality, and performance metrics.
</success_criteria>

<output>
After completion, create `.planning/phases/01-embedding-migration/01-04-SUMMARY.md`
</output>
